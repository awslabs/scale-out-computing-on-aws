# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
# SPDX-License-Identifier: Apache-2.0

# SCHEDULER_VARS are forwarded from templates/linux/schedulers/install_schedulers.sh.j2:

# Begin: OpenPBS Configure Server
function openpbs_configure_server_{{  SCHEDULER_VARS.get("IDENTIFIER") }} () {
    log_info "[BEGIN] openpbs_configure_server .. "
    local SCHEDULER_HOSTNAME="{{ SCHEDULER_VARS.get("ENDPOINT") }}"
    local SCHEDULER_IDENTIFIER="{{ SCHEDULER_VARS.get("IDENTIFIER") }}"
    local SOCA_CLUSTER_ID="{{ context.get("/configuration/ClusterId") }}"
    local SOCA_BASE_OS="{{ context.get("/configuration/BaseOS") }}"
    local OPENPBS_INSTALL_DIR="{{ SCHEDULER_VARS.get("PBS_CONFIGURATION").get("install_prefix_path") }}"
    local OPENPBS_PBS_HOME="{{ SCHEDULER_VARS.get("PBS_CONFIGURATION").get("pbs_home") }}"



    cp ${OPENPBS_PBS_HOME}/pbs.conf ${OPENPBS_PBS_HOME}/pbs.conf.original.$(date +%s)
    echo "PBS_SERVER=${SCHEDULER_HOSTNAME}
PBS_START_SERVER=1
PBS_START_SCHED=1
PBS_START_COMM=1
PBS_START_MOM=0
PBS_EXEC=${OPENPBS_INSTALL_DIR}
PBS_HOME=${OPENPBS_PBS_HOME}
PBS_CORE_LIMIT=unlimited
PBS_SCP=/usr/bin/scp
" > ${OPENPBS_PBS_HOME}/pbs.conf
    echo "\$clienthost ${SCHEDULER_HOSTNAME}" > ${OPENPBS_PBS_HOME}/mom_priv/config

    # to be removed after we switch to SOCA Multi Scheduler framework (eg: new dispatcher)
    # new framework will export PBS_CONF_FILE for all commands and won't rely on the default and incorrect /etc/pbs.conf
    cp -f "${OPENPBS_PBS_HOME}/pbs.conf" /etc/pbs.conf

    # Point to the correct PBS.conf
    export PBS_CONF_FILE="${OPENPBS_PBS_HOME}/pbs.conf"
    
    # Default AWS Resources
    cat <<EOF >>"${OPENPBS_PBS_HOME}/server_priv/resourcedef"
asg_spotfleet_id type=string
availability_zone type=string
base_os type=string
compute_node type=string flag=h
capacity_reservation_id type=string
efa_support type=string
error_message type=string
force_ri type=string
fsx_lustre type=string
fsx_lustre_deployment_type type=string
fsx_lustre_per_unit_throughput type=string
fsx_lustre_size type=string
ht_support type=string
instance_profile type=string
instance_ami type=string
instance_id type=string
instance_type type=string
instance_type_used type=string
keep_ebs type=string
placement_group type=string
root_size type=string
scratch_iops type=string
scratch_size type=string
security_groups type=string
spot_allocation_count type=string
spot_allocation_strategy type=string
spot_price type=string
stack_id type=string
subnet_id type=string
retry_attempt type=string
terminate_when_idle type=string flag=h
keep_forever type=string flag=h
EOF
    
    log_info "Starting  soca_scheduler_${SCHEDULER_IDENTIFIER}.service"
    systemctl enable soca_scheduler_${SCHEDULER_IDENTIFIER}.service
    if ! systemctl start soca_scheduler_${SCHEDULER_IDENTIFIER}.service; then
        journalctl -xeu soca_scheduler_${SCHEDULER_IDENTIFIER}.service
        exit_fail "Unable to start OpenPBS via soca_scheduler_${SCHEDULER_IDENTIFIER}.service, check logs"
    fi
    
    sleep 30

    # Create Default PBS hooks
    for queue_hook_file in /opt/soca/"${SOCA_CLUSTER_ID}"/cluster_hooks/pbs/queuejob/*.py;
    do
      hook_name=$(basename "${queue_hook_file}" | cut -f1 -d.)
      if [ "${hook_name}" == "check_project_budget" ]; then
        log_info "Skipping ${hook_name} from auto-creation. Manually configure and load the hook if needed"
        continue
      fi
      log_info "Creating hook ${hook_name} from ${queue_hook_file}"
      # FIXME / TODO - This needs to be fixed. Users should be able to validate checksums on files, and this breaks that
      # Hooks need to be converted to be smarter about where they are and the directory locations
      sed -i "s/%SOCA_CLUSTER_ID/${SOCA_CLUSTER_ID}/g" "${queue_hook_file}"
      ${OPENPBS_INSTALL_DIR}/bin/qmgr -c "create hook ${hook_name} event=queuejob"
      ${OPENPBS_INSTALL_DIR}/bin/qmgr -c "import hook ${hook_name} application/x-python default ${queue_hook_file}"
    done

    # Scheduler node creation
    ${OPENPBS_INSTALL_DIR}/bin/qmgr -c "create node ${SCHEDULER_HOSTNAME}"
    ${OPENPBS_INSTALL_DIR}/bin/qmgr -c "set node ${SCHEDULER_HOSTNAME} queue = workq"

    # Default Server config settings
    # Should probably find a better place for these
    declare -A qmgr_configs
    qmgr_configs["flatuid"]="true"
    qmgr_configs["job_history_enable"]="1"
    qmgr_configs["job_history_duration"]="72:00:00"
    qmgr_configs["scheduler_iteration"]="30"
    qmgr_configs["max_concurrent_provision"]="5000"
    qmgr_configs["python_restart_max_hooks"]="9999999"

    for config_key in "${!qmgr_configs[@]}"
    do
        log_info "Setting Qmgr configuration key (${config_key}) => (${qmgr_configs[${config_key}]})"
        ${OPENPBS_INSTALL_DIR}/bin/qmgr -c "set server ${config_key}=${qmgr_configs[${config_key}]}"
    done

    # Default Queue Configs
    for queue_name in low normal high job-shared test alwayson;
    do
      log_info "Creating queue ${queue_name}"
      ${OPENPBS_INSTALL_DIR}/bin/qmgr -c "create queue ${queue_name}"
      ${OPENPBS_INSTALL_DIR}/bin/qmgr -c "set queue ${queue_name} queue_type = Execution"
      ${OPENPBS_INSTALL_DIR}/bin/qmgr -c "set queue ${queue_name} started = True"
      ${OPENPBS_INSTALL_DIR}/bin/qmgr -c "set queue ${queue_name} enabled = True"
      # Alwayson special case - no compute_node=tbd setting needed
      if [[ "${queue_name}" != "alwayson" ]]; then
        ${OPENPBS_INSTALL_DIR}/bin/qmgr -c "set queue ${queue_name} default_chunk.compute_node=tbd"
      fi
    done

    ${OPENPBS_INSTALL_DIR}/bin/qmgr -c "set server default_queue = normal"

    # Add compute_node to list of required resource
    sed -i 's/resources: "ncpus, mem, arch, host, vnode, aoe, eoe"/resources: "ncpus, mem, arch, host, vnode, aoe, eoe, compute_node"/g' ${OPENPBS_PBS_HOME}/sched_priv/sched_config
    
    log_info "Restarting soca_scheduler_${SCHEDULER_IDENTIFIER}.service"
    if ! systemctl restart soca_scheduler_${SCHEDULER_IDENTIFIER}.service; then
        journalctl -xeu soca_scheduler_${SCHEDULER_IDENTIFIER}.service
        exit_fail "Unable to restart OpenPBS via soca_scheduler_${SCHEDULER_IDENTIFIER}.service, check logs"
    fi
    sleep 30
    log_info "[END] openpbs_configure_server .. "
}

openpbs_configure_server_{{  SCHEDULER_VARS.get("IDENTIFIER") }}
# End: OpenPBS Configure Server
